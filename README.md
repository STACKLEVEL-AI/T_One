# T_One - RAG-сервис для FAQ-поддержки

T_One — это RAG-сервис, который позволяет быстро развернуть систему "вопрос-ответ" по корпоративному FAQ без разметки и долгого обучения моделей. Источник знаний — Excel-таблица с официальными шаблонными ответами. Решение обеспечивает строгое соответствие коммуникациям из FAQ, предсказуемость, управляемую стоимость и низкую интеграционную сложность.

## Архитектура

T_One состоит из следующих компонентов:

- **FastAPI-приложение** (`combined_service.py`) — REST/HTTP слой с эндпоинтами `/api/*`, `/search`, `/admin/*`, `/health`, с валидацией моделей через Pydantic
- **Excel Reader** — `pandas` + `openpyxl` для чтения FAQ-таблицы
- **Индексатор** — преобразует строки Excel в документы с метаданными, готовит стабильные идентификаторы (`faq_{row}_{sha1}`)
- **Эмбеддинговый провайдер** — SciBox `/v1/embeddings` (модель по умолчанию `bge-m3`)
- **Векторное хранилище** — **ChromaDB** (persistent, папка `PERSIST_DIR`, коллекция `COLLECTION_NAME`)
- **LLM-провайдер** — SciBox `/v1/chat/completions` для выбора релевантных чанков (rerank) и опциональной генерации ответа
- **Кэш в памяти** — временное хранение результатов семантического поиска (TTL ≈ 10 минут)
- **Конфигурация** — `.env` (ключи, базовые URL, пути, имя коллекции, модель эмбеддингов и т.п.)
- **Наблюдаемость** — логи старта/инжеста/поиска/LLM-вызовов, счётчики токенов (если включены)

## Технологический стек

- **Python 3.13** (в Docker образе), локально — Python 3.13
- **FastAPI** + **Uvicorn** — HTTP API
- **ChromaDB** (persistent client) — хранение эмбеддингов/векторов
- **SciBox** (OpenAI-совместимый API) — эмбеддинги (`/v1/embeddings`) и LLM (`/v1/chat/completions`)
- **Pandas**, **openpyxl** — чтение Excel
- **Pydantic** — модели запросов/ответов
- **React** + **TypeScript** — фронтенд интерфейс
- **Tailwind CSS** — стилизация
- **Docker** / **Docker Compose** — контейнеризация и оркестрация

## Возможности

- Импорт FAQ из Excel и индексация во **векторной БД ChromaDB**
- **Семантический поиск** релевантных записей (модель эмбеддингов `bge-m3` через SciBox)
- **Выбор лучших чанков с помощью LLM** (prompt выбирает до 2–3 `faq_...` документов)
- **Генерация ответа** на основе шаблона из FAQ (или fallback-правила)
- Набор **админ-эндпоинтов**: первичная загрузка, сброс/пересборка коллекции, проверка поиска
- Полная локальная работа через Python, а также через Docker / docker compose
- **Фронтенд интерфейс** для пользователей и администраторов поддержки

## Структура проекта

```
T_One/
├── compose.yml
├── .env.example
├── .gitignore
├── README.md
├── hakaton_back/
│   ├── combined_service.py
│   ├── dockerfile
│   ├── requirements.txt
│   ├── pyproject.toml
│   ├── .env.example
│   ├── .dockerignore
│   └── _smart_support_vtb_belarus_faq_final.xlsx
└── hakaton_front/
    ├── Dockerfile
    ├── package.json
    ├── tsconfig.json
    ├── vite.config.ts
    ├── .env.example
    ├── .prettierrc.json
    ├── components.json
    ├── eslint.config.js
    ├── public/
    └── src/
        ├── App.tsx
        ├── api/
        ├── components/
        ├── types.ts
        ├── utils/
        └── queryClient.ts
```

## Запуск проекта

### 1) Подготовка окружения

Скопируйте `.env.example` в `.env` и заполните токен:

```bash
cp .env.example .env
# Обязательно укажите свой ключ
# SCIBOX_API_KEY=...
```

Обязательные переменные:
- `SCIBOX_API_KEY` — токен SciBox (обязательно)
- при необходимости можно переопределить пути/имена коллекции

### 2) Запуск через Docker Compose

```bash
docker compose up --build
```

Compose монтирует `./chroma_vtb` и Excel-файл, читает переменные из `.env` и публикует порты:
- Backend: `8001` (API)
- Frontend: `8080` (React dev server)

## API Эндпоинты

### Health
- `GET /api/health` → `{ "ok": true }`
- `GET /health` → `{ "status": "healthy" }`

### Сообщения (демо-чат)
- `GET /api/messages` — список созданных сообщений (ин-мемори)
- `POST /api/messages` — создание нового сообщения с классификацией и предложением ответа

### Поиск
- `GET /search?query=Текст&k=8`
- `POST /search` — семантический поиск по FAQ

### Получить ответ LLM без сохранения
- `POST /api/llm-response` — получить ответ LLM на основе FAQ

### Админ-эндпоинты
- `POST /admin/reset-db` — удалить и создать коллекцию заново
- `GET  /admin/excel-content` — показать первые строки Excel
- `POST /admin/reload-excel` — принудительно перечитать Excel и перезагрузить коллекцию
- `POST /admin/test-search` — прогон тестового запроса

## Пользовательские сценарии

1. **Поддержка клиентов (FAQ)**: восстановление доступа, статусы операций, лимиты и т.п.
2. **Внутренний справочник**: ответы для операторов/агентов в едином стиле
3. **Подготовка бота/виджета**: бэкенд для веб-чата

## Ключевые свойства

- **Простота ввода знаний**: достаточно Excel-файла
- **Контролируемость ответа**: идёт от шаблона, а не "галлюцинаций"
- **Издержки под контролем**: стоимость прозрачно рассчитывается
- **Локальная работа**: векторное хранилище на диске, без внешних БД
- **Контейнеризация**: Docker / Compose, быстрое развертывание
- **Удобный интерфейс**: фронтенд для пользователей и администраторов

## Нефункциональные требования

- **Латентность**: P95 ≤ 800–1200 мс
- **Доступность**: ≥ 99.5% при работе в одном регионе
- **Безопасность**: секреты только через `.env`/Secret Manager; PII не логируется
- **Наблюдаемость**: логи, счётчики токенов, метрики кэша

## Ограничения и риски

- **Покрытие ответов** зависит от полноты Excel
- **Качество семантики** зависит от выбранной модели эмбеддингов
- **Консистентность** в кластере при локальном кэше — использовать Redis, если много реплик